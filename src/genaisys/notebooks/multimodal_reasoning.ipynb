{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-02T20:26:20.676475Z",
     "start_time": "2026-01-02T20:26:19.386255Z"
    }
   },
   "source": [
    "import requests\n",
    "from openai import OpenAI\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from genaisys import make_openai_api_call, init_openai_api\n",
    "\n",
    "import base64\n",
    "\n",
    "# Implemented in Chapter06\n",
    "def make_openai_reasoning_call(user_text, mrole):\n",
    "  system_prompt=mrole\n",
    "  client = init_openai_api()\n",
    "  rmodel = \"o3-mini\" # o1 or other models. model defined in this file in /commons to make a global change to all the notebooks in the repo when there is an OpenAI update\n",
    "  response = client.chat.completions.create(\n",
    "      model=rmodel,\n",
    "      messages=[\n",
    "          {\"role\": \"system\", \"content\": system_prompt},\n",
    "          {\"role\": \"user\", \"content\": user_text}\n",
    "      ],\n",
    "  )\n",
    "  return response.choices[0].message.content\n",
    "\n",
    "def image_analysis(image_path_or_url, query_text, model=\"gpt-4o\"):\n",
    "\n",
    "    # Initialize the content list with the query text\n",
    "    content = [{\"type\": \"text\", \"text\": query_text}]\n",
    "\n",
    "    if image_path_or_url.startswith((\"http://\", \"https://\")):\n",
    "        # It's a URL; add it to the content\n",
    "        content.append({\"type\": \"image_url\", \"image_url\": {\"url\": image_path_or_url}})\n",
    "    else:\n",
    "        # It's a local file; read and encode the image data\n",
    "        with open(image_path_or_url, \"rb\") as image_file:\n",
    "            image_data = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "        # Create a data URL for the image\n",
    "        data_url = f\"data:image/png;base64,{image_data}\"\n",
    "        content.append({\"type\": \"image_url\", \"image_url\": {\"url\": data_url}})\n",
    "\n",
    "    # Create the message object\n",
    "    messages = [{\"role\": \"user\", \"content\": content}]\n",
    "\n",
    "    # Define the parameters\n",
    "    params = {\n",
    "        \"max_tokens\": 300,\n",
    "        \"temperature\": 0,\n",
    "        \"top_p\": 1,\n",
    "        \"frequency_penalty\": 0,\n",
    "        \"presence_penalty\": 0,\n",
    "    }\n",
    "    client = init_openai_api()\n",
    "    # Make the API call\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        **params  # Unpack the parameters dictionary\n",
    "    )\n",
    "\n",
    "    # Save the result to a file\n",
    "    with open(\"image_text.txt\", \"w\") as file:\n",
    "        file.write(response.choices[0].message.content)\n",
    "\n",
    "    # Return the response content\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Implemented in Chapter05\n",
    "def generate_image(prompt, model=\"dall-e-3\", size=\"1024x1024\", quality=\"standard\", n=1):\n",
    "\n",
    "    # Initialize the OpenAI client\n",
    "    client = OpenAI()\n",
    "\n",
    "    # Generate the image using the OpenAI API\n",
    "    response = client.images.generate(\n",
    "        model=model,\n",
    "        prompt=prompt,\n",
    "        size=size,\n",
    "        quality=quality,\n",
    "        n=n,\n",
    "    )\n",
    "\n",
    "    # Extract and return the image URL from the response\n",
    "    return response.data[0].url\n",
    "\n",
    "# Import the function from custom machine learning file\n",
    "import os\n",
    "from genaisys.machine_learning import ml_agent\n",
    "\n",
    "from ipywidgets import Output, VBox, Layout\n",
    "import time\n",
    "\n",
    "# Create an output widget for reasoning steps\n",
    "reasoning_output = Output(layout=Layout(border=\"1px solid black\", padding=\"10px\", margin=\"10px\", width=\"100%\"))\n",
    "\n",
    "def chain_of_thought_reasoning(initial_query):\n",
    "    steps = []\n",
    "\n",
    "    # Display the reasoning_output widget in the interface\n",
    "    display(reasoning_output)\n",
    "\n",
    "    # Step 1: Analysis of the customer database and prediction\n",
    "    steps.append(\"Process: Performing machine learning analysis of the customer database. \\n\")\n",
    "    with reasoning_output:\n",
    "        reasoning_output.clear_output(wait=True)\n",
    "        print(steps[-1])  # Print the current step\n",
    "    time.sleep(2)  # Simulate processing time\n",
    "    result_ml = ml_agent(\"\", \"ACTIVITY\")\n",
    "    steps.append(f\"Machine learning analysis result: {result_ml}\")\n",
    "\n",
    "    # Step 2: Searching for activities that fit customer needs\n",
    "    steps.append(\"Process: Searching for activities that fit the customer needs. \\n\")\n",
    "    with reasoning_output:\n",
    "        reasoning_output.clear_output(wait=True)\n",
    "        print(steps[-1])\n",
    "    time.sleep(2)\n",
    "    umessage = (\n",
    "        \"What activities could you suggest to provide more activities and excitement in holiday trips.\"\n",
    "        + result_ml\n",
    "    )\n",
    "    mrole = \"system\"\n",
    "    mcontent = (\n",
    "        \"You are an assistant that explains your reasoning step by step before providing the answer. \"\n",
    "        \"Use structured steps to break down the query.\"\n",
    "    )\n",
    "    user_role = \"user\"\n",
    "    task_response = make_openai_api_call(umessage, mrole, mcontent, user_role)\n",
    "    steps.append(f\"Activity suggestions: {task_response}\")\n",
    "\n",
    "    # Step 3: Generating an image based on the ideation\n",
    "    steps.append(\"Process: Generating an image based on the ideation. \\n\")\n",
    "    with reasoning_output:\n",
    "        reasoning_output.clear_output(wait=True)\n",
    "        print(steps[-1])\n",
    "    time.sleep(2)\n",
    "    prompt = task_response\n",
    "    image_url = generate_image(prompt)\n",
    "    steps.append(f\"Generated Image URL: {image_url}\")\n",
    "    save_path = \"c_image.png\"\n",
    "    image_data = requests.get(image_url).content\n",
    "    with open(save_path, \"wb\") as file:\n",
    "        file.write(image_data)\n",
    "    steps.append(f\"Image saved as {save_path}\")\n",
    "\n",
    "    # Step 4: Providing an engaging story based on the generated image\n",
    "    steps.append(\"Process: Providing an engaging story based on the generated image. \\n\")\n",
    "    with reasoning_output:\n",
    "        reasoning_output.clear_output(wait=True)\n",
    "        print(steps[-1])\n",
    "    time.sleep(2)\n",
    "    query_text = \"Providing an engaging story based on the generated image\"\n",
    "    response = image_analysis(image_url, query_text)\n",
    "    steps.append(f\"Story response: {response}\")\n",
    "\n",
    "    # Clear output and notify completion\n",
    "    with reasoning_output:\n",
    "        reasoning_output.clear_output(wait=True)\n",
    "        print(\"All steps completed!\")\n",
    "    return steps\n",
    "\n",
    "# Implemented in Chapter06\n",
    "def extract(retres):\n",
    "  umessage = \"\"\"\n",
    "  1) Read the following text analysis that returns detailled memory tags for each part of the text\n",
    "  2) Then return the list of memory tags with absolutely no other text\n",
    "  3) Use no formatting, no hastages, no markdown. Just answer in plain text\n",
    "  4) Also provide the sentiment analysis score for each tag in this format(no brackets) : memory tag sentiment Score\n",
    "  \"\"\"\n",
    "  umessage+=retres\n",
    "  mrole = \"system\"\n",
    "  mcontent = \"You are a marketing expert specialized in the psychological analysis of content\"\n",
    "  user_role = \"user\"\n",
    "  task_response = make_openai_api_call(umessage,mrole,mcontent,user_role)\n",
    "  return task_response\n",
    "\n",
    "def memory_reasoning_thread(input1,system_message_s1,umessage4,imcontent4,imcontent4b):\n",
    "  steps = []\n",
    "\n",
    "  # Display the VBox in the interface\n",
    "  display(reasoning_output)\n",
    "\n",
    "  # Step 1. Memory and sentiment analysis\n",
    "  steps.append(\"Process: Performing memory and sentiment analysis.\\n\")\n",
    "  with reasoning_output:\n",
    "        reasoning_output.clear_output(wait=True)\n",
    "        print(steps[-1])  # Print the current step\n",
    "  # API call\n",
    "  mrole=system_message_s1\n",
    "  user_text=input1\n",
    "  user_role = \"user\"\n",
    "  retres=make_openai_reasoning_call(user_text, mrole)\n",
    "  steps.append(f\"Memory analysis result: {retres}\")\n",
    "\n",
    "  # Step 2. Extract scores\n",
    "  steps.append(\"Process: Extracting scores from response.\\n\")\n",
    "  with reasoning_output:\n",
    "        reasoning_output.clear_output(wait=True)\n",
    "        print(steps[-1])  # Print the current step\n",
    "  task_response=extract(retres)\n",
    "  steps.append(f\"Memory analysis result: {task_response}\")\n",
    "\n",
    "  # Step 3 : Statistics\n",
    "  steps.append(\"Process: Statistical analysis\\n\")\n",
    "  with reasoning_output:\n",
    "        reasoning_output.clear_output(wait=True)\n",
    "        print(steps[-1])  # Print the current step\n",
    "\n",
    "  import re\n",
    "  # Input text\n",
    "  text=task_response\n",
    "\n",
    "  # Regular expression to extract sentiment scores\n",
    "  pattern = r\"(\\d+\\.\\d+)\"\n",
    "  scores = [float(match) for match in re.findall(pattern, text)]\n",
    "\n",
    "  # Output the extracted scores\n",
    "  steps.append(f\"Extracted sentiment scores: {scores}\")\n",
    "\n",
    "  # Optional: calculate the overall score and scaled rating\n",
    "  if scores:\n",
    "    overall_score = sum(scores) / len(scores)\n",
    "    overall_score = round(overall_score, 2)\n",
    "    scaled_rating = overall_score * 5\n",
    "    scaled_rating = round(scaled_rating, 2)\n",
    "\n",
    "    steps.append(f\"Extracted sentiment scores: {overall_score}\")\n",
    "    steps.append(f\"Scaled rating (0â€“5): {scaled_rating}\")\n",
    "\n",
    "  #Step 4: Creating content\n",
    "  steps.append(\"Process: Creating content\\n\")\n",
    "  with reasoning_output:\n",
    "        reasoning_output.clear_output(wait=True)\n",
    "        print(steps[-1])  # Print the current step\n",
    "\n",
    "  #Step 4: Creating content\n",
    "  ugeneration=umessage4 + \"The advanced memory analysis of each segment of a text with a sentiment score:\" + retres + \" the scaled overall rating: \"+ str(scaled_rating)+ \" and the list of memory tags of the text \"+ task_response\n",
    "  mrole4 = \"system\"\n",
    "  mcontent4 = imcontent4\n",
    "  user_role = \"user\"\n",
    "  pre_creation_response = make_openai_api_call(ugeneration,mrole4,mcontent4,user_role)\n",
    "\n",
    "  umessage4b=\"Clean and simplify the following text for use as a DALL-E prompt. Focus on converting the detailed analysis into a concise visual description suitable for generating an engaging promotional image\" + pre_creation_response\n",
    "  mrole4b = \"system\"\n",
    "  mcontent4b = imcontent4b\n",
    "  user_role4b = \"user\"\n",
    "  creation_response = make_openai_api_call(umessage4b,mrole4b,mcontent4b,user_role4b)\n",
    "  steps.append(f\"Prompt created for image generation: {creation_response}\")\n",
    "\n",
    "\n",
    "  # Step 5: Creating an image\n",
    "  steps.append(\"Process: Creating an image\\n\")\n",
    "  with reasoning_output:\n",
    "        reasoning_output.clear_output(wait=True)\n",
    "        print(steps[-1])  # Print the current step\n",
    "\n",
    "  import requests\n",
    "  prompt=creation_response\n",
    "  image_url = generate_image(prompt)\n",
    "  save_path = \"c_image.png\"\n",
    "  image_data = requests.get(image_url).content\n",
    "  with open(save_path, \"wb\") as file:\n",
    "    file.write(image_data)\n",
    "  steps.append(f\"Image created\")\n",
    "\n",
    "  # Step 6: Creating a message\n",
    "  steps.append(\"Process: Creating a message.\\n\")\n",
    "  with reasoning_output:\n",
    "        reasoning_output.clear_output(wait=True)\n",
    "        print(steps[-1])  # Print the current step\n",
    "\n",
    "  umessage6 = \"\"\"\n",
    "  1) Read the following text carefully\n",
    "  2) Then sum it up in a paragraphs without numbering the lines\n",
    "  3) They output should be a text to send to a customer\n",
    "  \"\"\"\n",
    "  umessage6b=creation_response\n",
    "  mrole6 = \"system\"\n",
    "  mcontent6 = \"You are an expert in summarization for texts to send to a customer.Begin with Dear Customer and finish with Best regards\"\n",
    "  user_role6b = \"user\"\n",
    "  process_response = make_openai_api_call(umessage6b,mrole6,mcontent6,user_role6b)\n",
    "  steps.append(f\"Customer message: {process_response}\")\n",
    "\n",
    "  return steps\n",
    "\n",
    "# Implemented in Chapter05\n",
    "def chain_of_thought_reasoning(initial_query):\n",
    "    steps = []\n",
    "\n",
    "    # Display the reasoning_output widget in the interface\n",
    "    display(reasoning_output)\n",
    "\n",
    "    # Step 1: Analysis of the customer database and prediction\n",
    "    steps.append(\"Process: Performing machine learning analysis of the customer database. \\n\")\n",
    "    with reasoning_output:\n",
    "        reasoning_output.clear_output(wait=True)\n",
    "        print(steps[-1])  # Print the current step\n",
    "    time.sleep(2)  # Simulate processing time\n",
    "    result_ml = ml_agent(\"\", \"ACTIVITY\")\n",
    "    steps.append(f\"Machine learning analysis result: {result_ml}\")\n",
    "\n",
    "    # Step 2: Searching for activities that fit customer needs\n",
    "    steps.append(\"Process: Searching for activities that fit the customer needs. \\n\")\n",
    "    with reasoning_output:\n",
    "        reasoning_output.clear_output(wait=True)\n",
    "        print(steps[-1])\n",
    "    time.sleep(2)\n",
    "    umessage = (\n",
    "        \"What activities could you suggest to provide more activities and excitement in holiday trips.\"\n",
    "        + result_ml\n",
    "    )\n",
    "    mrole = \"system\"\n",
    "    mcontent = (\n",
    "        \"You are an assistant that explains your reasoning step by step before providing the answer. \"\n",
    "        \"Use structured steps to break down the query.\"\n",
    "    )\n",
    "    user_role = \"user\"\n",
    "    task_response = make_openai_api_call(umessage, mrole, mcontent, user_role)\n",
    "    steps.append(f\"Activity suggestions: {task_response}\")\n",
    "\n",
    "    # Step 3: Generating an image based on the ideation\n",
    "    steps.append(\"Process: Generating an image based on the ideation. \\n\")\n",
    "    with reasoning_output:\n",
    "        reasoning_output.clear_output(wait=True)\n",
    "        print(steps[-1])\n",
    "    time.sleep(2)\n",
    "    prompt = task_response\n",
    "    image_url = generate_image(prompt)\n",
    "    steps.append(f\"Generated Image URL: {image_url}\")\n",
    "    save_path = \"c_image.png\"\n",
    "    image_data = requests.get(image_url).content\n",
    "    with open(save_path, \"wb\") as file:\n",
    "        file.write(image_data)\n",
    "    steps.append(f\"Image saved as {save_path}\")\n",
    "\n",
    "    # Step 4: Providing an engaging story based on the generated image\n",
    "    steps.append(\"Process: Providing an engaging story based on the generated image. \\n\")\n",
    "    with reasoning_output:\n",
    "        reasoning_output.clear_output(wait=True)\n",
    "        print(steps[-1])\n",
    "    time.sleep(2)\n",
    "    query_text = \"Providing an engaging story based on the generated image\"\n",
    "    response = image_analysis(image_url, query_text)\n",
    "    steps.append(f\"Story response: {response}\")\n",
    "\n",
    "    # Clear output and notify completion\n",
    "    with reasoning_output:\n",
    "        reasoning_output.clear_output(wait=True)\n",
    "        print(\"All steps completed!\")\n",
    "    return steps\n",
    "\n",
    "# Implemented in Chapter08\n",
    "def mobility_agent_reasoning_thread(input1,msystem_message_s1,mumessage4,mimcontent4,mimcontent4b):\n",
    "  steps = []\n",
    "\n",
    "  # Display the VBox in the interface\n",
    "  display(reasoning_output)\n",
    "\n",
    "  #Step 1: Mobility agent\n",
    "  steps.append(\"Process: the mobility agent is thinking\\n\")\n",
    "  with reasoning_output:\n",
    "        reasoning_output.clear_output(wait=True)\n",
    "        print(steps[-1])  # Print the current step\n",
    "\n",
    "  mugeneration=msystem_message_s1 + input1\n",
    "  mrole4 = \"system\"\n",
    "  mcontent4 = mimcontent4\n",
    "  user_role = \"user\"\n",
    "  create_response = make_openai_api_call(mugeneration,mrole4,mcontent4,user_role)\n",
    "  steps.append(f\"Customer message: {create_response}\")\n",
    "\n",
    "  return steps\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
