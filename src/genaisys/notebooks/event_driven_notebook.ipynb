{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-01T22:07:16.544299Z",
     "start_time": "2026-01-01T22:07:16.452355Z"
    }
   },
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "\n",
    "from IPython.display import display, HTML, clear_output\n",
    "from ipywidgets import Dropdown, Text, Checkbox, Layout, Button, HBox, Output\n",
    "\n",
    "# Add the src directory to the path\n",
    "src_path = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n",
    "\n",
    "from genaisys import init_openai_api, make_openai_api_call\n",
    "from genaisys.querying_functions import get_query_result, display_results\n",
    "\n",
    "# ============ SHARED STATE ============\n",
    "user_histories = {\"User01\": [], \"User02\": [], \"User03\": []}\n",
    "active_user = \"User01\"\n",
    "conversation_active = True\n",
    "\n",
    "# Create output widgets\n",
    "conversation_output = Output()\n",
    "debug_output = Output()\n",
    "user_memory = True\n",
    "\n",
    "# ============ FUNCTIONS ============\n",
    "\n",
    "def chat_with_gpt(messages, user_message):\n",
    "    \"\"\"Call GPT with optional RAG from Pinecone.\"\"\"\n",
    "    try:\n",
    "        namespace = \"\"\n",
    "        if \"Pinecone\" in user_message or \"RAG\" in user_message:\n",
    "            if \"Pinecone\" in user_message:\n",
    "                namespace = \"genaisys\"\n",
    "            elif \"RAG\" in user_message:\n",
    "                namespace = \"data01\"\n",
    "\n",
    "            with debug_output:\n",
    "                print(f\"DEBUG: Using namespace: {namespace}\")\n",
    "\n",
    "            query_results = get_query_result(user_message, namespace)\n",
    "            qtext, target_id = display_results(query_results)\n",
    "\n",
    "            sc_input = qtext + \" \" + user_message\n",
    "            task_response = make_openai_api_call(\n",
    "                sc_input, \"system\",\n",
    "                \"You are an assistant who executes the tasks you are asked to do.\",\n",
    "                \"user\"\n",
    "            )\n",
    "            return f\"{namespace}:{task_response}\"\n",
    "        else:\n",
    "            if user_memory:\n",
    "                user_messages_content = [\n",
    "                    msg[\"content\"] for msg in messages\n",
    "                    if msg[\"role\"] == \"user\" and \"content\" in msg\n",
    "                ]\n",
    "                combined = \" \".join(user_messages_content)\n",
    "                umessage = f\"{combined} {user_message}\"\n",
    "            else:\n",
    "                umessage = user_message\n",
    "\n",
    "            task_response = make_openai_api_call(\n",
    "                umessage, \"system\",\n",
    "                \"You are an assistant who executes the tasks you are asked to do.\",\n",
    "                \"user\"\n",
    "            )\n",
    "            return task_response\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {e}\"\n",
    "\n",
    "\n",
    "def save_conversation_history():\n",
    "    \"\"\"Save conversation history to JSON file.\"\"\"\n",
    "    filename = \"conversation_history.json\"\n",
    "    with open(filename, 'w') as file:\n",
    "        json.dump(user_histories, file, indent=4)\n",
    "    display(HTML(f\"<div style='color: green;'><strong>Saved to {filename}</strong></div>\"))\n",
    "\n",
    "\n",
    "def update_display():\n",
    "    \"\"\"Update the conversation display.\"\"\"\n",
    "    global active_user\n",
    "    with debug_output:\n",
    "        print(f\"DEBUG: update_display() - Active user: {active_user}\")\n",
    "        print(f\"DEBUG: History entries: {len(user_histories[active_user])}\")\n",
    "\n",
    "    with conversation_output:\n",
    "        clear_output(wait=True)\n",
    "        for entry in user_histories[active_user]:\n",
    "            if entry['role'] == 'user':\n",
    "                display(HTML(\n",
    "                    f\"<div style='margin-left: 20px; color: blue; margin-bottom: 5px;'>\"\n",
    "                    f\"<strong>{active_user}:</strong> {entry['content']}</div>\"\n",
    "                ))\n",
    "            elif entry['role'] == 'assistant':\n",
    "                display(HTML(\n",
    "                    f\"<div style='margin-left: 20px; color: green; margin-bottom: 5px;'>\"\n",
    "                    f\"<strong>Agent:</strong> {entry['content']}</div>\"\n",
    "                ))\n",
    "\n",
    "\n",
    "def chat(user_message):\n",
    "    \"\"\"Handle user input and generate response.\"\"\"\n",
    "    global active_user, conversation_active\n",
    "\n",
    "    with debug_output:\n",
    "        print(f\"DEBUG: chat() called with: '{user_message}'\")\n",
    "\n",
    "    # Check for exit\n",
    "    if user_message.lower() in ['exit', 'quit']:\n",
    "        conversation_active = False\n",
    "        with conversation_output:\n",
    "            clear_output()\n",
    "            display(HTML(\"<div style='color: red;'><strong>Conversation ended.</strong></div>\"))\n",
    "            save_conversation_history()\n",
    "        return\n",
    "\n",
    "    # Add user message to history\n",
    "    user_histories[active_user].append({\"role\": \"user\", \"content\": user_message})\n",
    "\n",
    "    # Generate response if agent is enabled\n",
    "    if agent_checkbox.value:\n",
    "        with debug_output:\n",
    "            print(\"DEBUG: Generating agent response...\")\n",
    "        try:\n",
    "            response = chat_with_gpt(user_histories[active_user], user_message)\n",
    "            with debug_output:\n",
    "                print(f\"DEBUG: Response: '{response[:100]}...'\")\n",
    "            user_histories[active_user].append({\"role\": \"assistant\", \"content\": response})\n",
    "        except Exception as e:\n",
    "            with debug_output:\n",
    "                print(f\"DEBUG: Error: {e}\")\n",
    "            user_histories[active_user].append({\"role\": \"assistant\", \"content\": f\"Error: {e}\"})\n",
    "    else:\n",
    "        with debug_output:\n",
    "            print(\"DEBUG: Agent disabled, skipping response\")\n",
    "\n",
    "    update_display()\n",
    "\n",
    "\n",
    "def on_user_change(change):\n",
    "    \"\"\"Handle user selection change.\"\"\"\n",
    "    global active_user\n",
    "    active_user = change['new']\n",
    "    with debug_output:\n",
    "        print(f\"DEBUG: User changed to: {active_user}\")\n",
    "    update_display()\n",
    "\n",
    "\n",
    "def handle_input(sender):\n",
    "    \"\"\"Handle input submission (Enter key or button).\"\"\"\n",
    "    user_message = input_box.value\n",
    "    with debug_output:\n",
    "        print(f\"DEBUG: Input received: '{user_message}'\")\n",
    "\n",
    "    if user_message and user_message.strip():\n",
    "        input_box.value = \"\"  # Clear input\n",
    "        chat(user_message)\n",
    "\n",
    "# Function to save conversation history to a file\n",
    "def save_conversation_history():\n",
    "    filename = \"conversation_history.json\"  # Define the filename\n",
    "    with open(filename, 'w') as file:\n",
    "        json.dump(user_histories, file, indent=4)  # Write the user histories dictionary to the file in JSON format\n",
    "    display(HTML(f\"<div style='color: green;'><strong>Conversation history saved to {filename}.</strong></div>\"))\n",
    "\n",
    "# ============ UI WIDGETS ============\n",
    "\n",
    "user_selector = Dropdown(\n",
    "    options=[\"User01\", \"User02\", \"User03\"],\n",
    "    value=active_user,\n",
    "    description='User:',\n",
    "    layout=Layout(width='200px')\n",
    ")\n",
    "user_selector.observe(on_user_change, names='value')\n",
    "\n",
    "input_box = Text(\n",
    "    placeholder=\"Type your message here and press Enter or click Send\",\n",
    "    layout=Layout(width='400px'),\n",
    "    continuous_update=False\n",
    ")\n",
    "input_box.observe(lambda change: handle_input(change) if change['name'] == 'value' and change['new'] else None, names='value')\n",
    "\n",
    "send_button = Button(\n",
    "    description='Send',\n",
    "    button_style='primary',\n",
    "    layout=Layout(width='80px')\n",
    ")\n",
    "send_button.on_click(lambda b: handle_input(b))\n",
    "\n",
    "agent_checkbox = Checkbox(\n",
    "    value=True,\n",
    "    description='Agent',\n",
    "    layout=Layout(width='100px')\n",
    ")\n",
    "\n",
    "# ============ DISPLAY INTERFACE ============\n",
    "\n",
    "display(HTML(\"<h3>GenAI Chat Interface</h3>\"))\n",
    "display(user_selector)\n",
    "display(HBox([input_box, send_button]))\n",
    "display(agent_checkbox)\n",
    "display(HTML(\"<hr><h4>Conversation:</h4>\"))\n",
    "display(conversation_output)\n",
    "display(HTML(\"<hr><h4>Debug Output:</h4>\"))\n",
    "display(debug_output)\n",
    "\n",
    "with debug_output:\n",
    "    print(\"DEBUG: Interface ready.\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<h3>GenAI Chat Interface</h3>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Dropdown(description='User:', layout=Layout(width='200px'), options=('User01', 'User02', 'User03'), value='Use…"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a88c869e72a244f4a12ebd987f924247"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "HBox(children=(Text(value='', continuous_update=False, layout=Layout(width='400px'), placeholder='Type your me…"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "17cc0b091f0d43539bf1607f0038fd86"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Checkbox(value=True, description='Agent', layout=Layout(width='100px'))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cc57947fbc8a406e81980c39328cc6c4"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<hr><h4>Conversation:</h4>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Output()"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "53c4721de99d41818dd438b955bef82d"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<hr><h4>Debug Output:</h4>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Output()"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "381908e293eb4ae49761853f2a2edc7c"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
